













































An Optimal-Time Binarization Algorithm for Linear Context-Free Rewriting Systems with Fan-Out Two


Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 985–993,
Suntec, Singapore, 2-7 August 2009. c©2009 ACL and AFNLP

An Optimal-Time Binarization Algorithm
for Linear Context-Free Rewriting Systems with Fan-Out Two

Carlos Gómez-Rodrı́guez
Departamento de Computación
Universidade da Coruña, Spain

cgomezr@udc.es

Giorgio Satta
Department of Information Engineering

University of Padua, Italy
satta@dei.unipd.it

Abstract

Linear context-free rewriting systems
(LCFRSs) are grammar formalisms with
the capability of modeling discontinu-
ous constituents. Many applications use
LCFRSs where the fan-out (a measure of
the discontinuity of phrases) is not allowed
to be greater than 2. We present an ef-
ficient algorithm for transforming LCFRS
with fan-out at most 2 into a binary form,
whenever this is possible. This results
in asymptotical run-time improvement for
known parsing algorithms for this class.

1 Introduction

Since its early years, the computational linguistics
field has devoted much effort to the development
of formal systems for modeling the syntax of nat-
ural language. There has been a considerable in-
terest in rewriting systems that enlarge the generat-
ive power of context-free grammars, still remain-
ing far below the power of the class of context-
sensitive grammars; see (Joshi et al., 1991) for dis-
cussion. Following this line, (Vijay-Shanker et al.,
1987) have introduced a formalism called linear
context-free rewriting systems (LCFRSs) that has
received much attention in later years by the com-
munity.

LCFRSs allow the derivation of tuples of
strings,1 i.e., discontinuous phrases, that turn out
to be very useful in modeling languages with rel-
atively free word order. This feature has recently
been used for mapping non-projective depend-
ency grammars into discontinuous phrase struc-
tures (Kuhlmann and Satta, 2009). Furthermore,
LCFRSs also implement so-called synchronous

1In its more general definition, an LCFRS provides a
framework where abstract structures can be generated, as for
instance trees and graphs. Throughout this paper we focus on
so-called string-based LCFRSs, where rewriting is defined
over strings only.

rewriting, up to some bounded degree, and have
recently been exploited, in some syntactic vari-
ant, in syntax-based machine translation (Chiang,
2005; Melamed, 2003) as well as in the modeling
of syntax-semantic interface (Nesson and Shieber,
2006).

The maximum number f of tuple components
that can be generated by an LCFRS G is called
the fan-out of G, and the maximum number r of
nonterminals in the right-hand side of a production
is called the rank of G. As an example, context-
free grammars are LCFRSs with f = 1 and r
given by the maximum length of a production
right-hand side. Tree adjoining grammars (Joshi
and Levy, 1977), or TAG for short, can be viewed
as a special kind of LCFRS with f = 2, since
each elementary tree generates two strings, and r
given by the maximum number of adjunction sites
in an elementary tree.

Several parsing algorithms for LCFRS or equi-
valent formalisms are found in the literature; see
for instance (Seki et al., 1991; Boullier, 2004; Bur-
den and Ljunglöf, 2005). All of these algorithms
work in time O(|G| · |w|f ·(r+1)). Parsing time is
then exponential in the input grammar size, since
|G| depends on both f and r. In the develop-
ment of efficient algorithms for parsing based on
LCFRS the crucial goal is therefore to optimize
the term f · (r + 1).

In practical natural language processing applic-
ations the fan-out of the grammar is typically
bounded by some small number. As an example,
in the case of discontinuous parsing discussed
above, we have f = 2 for most practical cases.
On the contrary, LCFRS productions with a rel-
atively large number of nonterminals are usually
observed in real data. The reduction of the rank of
a LCFRS, called binarization, is a process very
similar to the reduction of a context-free grammar
into Chomsky normal form. While in the special
case of CFG and TAG this can always be achieved,

985



binarization of an LCFRS requires, in the gen-
eral case, an increase in the fan-out of the gram-
mar much larger than the achieved reduction in
the rank. Worst cases and some lower bounds have
been discussed in (Rambow and Satta, 1999; Satta,
1998).

Nonetheless, in many cases of interest binariza-
tion of an LCFRS can be carried out without any
extra increase in the fan-out. As an example, in
the case where f = 2, binarization of a LCFRS
would result in parsing time of O(|G| · |w|6).
With the motivation of parsing efficiency, much
research has been recently devoted to the design
of efficient algorithms for rank reduction, in cases
in which this can be carried out at no extra increase
in the fan-out. (Gómez-Rodrı́guez et al., 2009) re-
ports a general binarization algorithm for LCFRS.
In the case where f = 2, this algorithm works
in time O(|p|7), where p is the input production.
A more efficient algorithm is presented in (Kuhl-
mann and Satta, 2009), working in time O(|p|) in
case of f = 2. However, this algorithm works
for a restricted typology of productions, and does
not cover all cases in which some binarization is
possible. Other linear time algorithms for rank re-
duction are found in the literature (Zhang et al.,
2008), but they are restricted to the case of syn-
chronous context-free grammars, a strict subclass
of the LCFRS with f = 2.

In this paper we focus our attention on LCFRS
with a fan-out of two. We improve upon all
of the above mentioned results, by providing
an algorithm that computes a binarization of an
LCFRS production in all cases in which this is
possible and works in time O(|p|). This is an
optimal result in terms of time complexity, since
Θ(|p|) is also the size of any output binarization
of an LCFRS production.

2 Linear context-free rewriting systems

We briefly summarize here the terminology and
notation that we adopt for LCFRS; for detailed
definitions, see (Vijay-Shanker et al., 1987). We
denote the set of non-negative integers by N. For
i, j ∈ N, the interval {k | i ≤ k ≤ j} is denoted
by [i, j]. We write [i] as a shorthand for [1, i]. For
an alphabet V , we write V ∗ for the set of all (fi-
nite) strings over V .

As already mentioned in Section 1, linear
context-free rewriting systems generate tuples of
strings over some finite alphabet. This is done by

associating each production p of a grammar with
a function g that rearranges the string compon-
ents in the tuples generated by the nonterminals
in p’s right-hand side, possibly adding some al-
phabet symbols. Let V be some finite alphabet.
For natural numbers r ≥ 0 and f, f1, . . . , fr ≥ 1,
consider a function g : (V ∗)f1 × · · · × (V ∗)fr →
(V ∗)f defined by an equation of the form

g(〈x1,1, . . . , x1,f1〉, . . . , 〈xr,1, . . . , xr,fr〉) = ~α,

where ~α = 〈α1, . . . , αf 〉 is an f -tuple of strings
over g’s argument variables and symbols in V . We
say that g is linear, non-erasing if ~α contains ex-
actly one occurrence of each argument variable.
We call r and f the rank and the fan-out of g, re-
spectively, and write r(g) and f(g) to denote these
quantities.

A linear context-free rewriting system
(LCFRS) is a tuple G = (VN , VT , P, S), where
VN and VT are finite, disjoint alphabets of nonter-
minal and terminal symbols, respectively. Each
A ∈ VN is associated with a value f(A), called its
fan-out. The nonterminal S is the start symbol,
with f(S) = 1. Finally, P is a set of productions
of the form

p : A→ g(A1, A2, . . . , Ar(g)) ,

where A,A1, . . . , Ar(g) ∈ VN , and g : (V ∗T )
f(A1)

× · · ·× (V ∗T )
f(Ar(g)) → (V ∗T )

f(A) is a linear, non-
erasing function.

A production p of G can be used to transform
a sequence of r(g) string tuples generated by the
nonterminals A1, . . . , Ar(g) into a tuple of f(A)
strings generated by A. The values r(g) and f(g)
are called the rank and fan-out of p, respectively,
written r(p) and f(p). The rank and fan-out of G,
written r(G) and f(G), respectively, are the max-
imum rank and fan-out among all of G’s produc-
tions. Given that f(S) = 1, S generates a set of
strings, defining the language of G.

Example 1 Consider the LCFRS G defined by
the productions

p1 : S → g1(A), g1(〈x1,1, x1,2〉) = 〈x1,1x1,2〉
p2 : A→ g2(A), g2(〈x1,1, x1,2〉) = 〈ax1,1b, cx1,2d〉
p3 : A→ g3(), g3() = 〈ε, ε〉

We have f(S) = 1, f(A) = f(G) = 2, r(p3) = 0
and r(p1) = r(p2) = r(G) = 1. G generates
the string language {anbncndn |n ∈ N}. For in-
stance, the string a3b3c3d3 is generated by means

986



of the following bottom-up process. First, the
tuple 〈ε, ε〉 is generated by A through p3. We
then iterate three times the application of p2 to
〈ε, ε〉, resulting in the tuple 〈a3b3, c3d3〉. Finally,
the tuple (string) 〈a3b3c3d3〉 is generated by S
through application of p1. 2

3 Position sets and binarizations

Throughout this section we assume an LCFRS
production p : A→ g(A1, . . . , Ar) with g defined
through a tuple ~α as in section 2. We also assume
that the fan-out ofA and the fan-out of eachAi are
all bounded by two.

3.1 Production representation
We introduce here a specialized representation for
p. Let $ be a fresh symbol that does not occur
in p. We define the characteristic string of p as
the string

σN (p) = α
′
1$α

′
2$ · · · $α

′
f(A),

where each α′j is obtained from αj by removing all
the occurrences of symbols in VT . Consider now
some occurrence Ai of a nonterminal symbol in
the right-hand side of p. We define the position set
of Ai, written XAi , as the set of all non-negative
integers j ∈ [|σN (p)|] such that the j-th symbol in
σN (p) is a variable of the form xi,h for some h.

Example 2 Let p : A → g(A1, A2, A3), where
g(〈x1,1, x1,2〉, 〈x2,1〉, 〈x3,1, x3,2〉) = ~α with

~α = 〈x1,1ax2,1x1,2, x3,1bx3,2〉 .

We have σN (p) = x1,1x2,1x1,2$x3,1x3,2, XA1 =
{1, 3}, XA2 = {2} and XA3 = {5, 6}. 2

Each position set X ⊆ [|σN (p)|] can be repres-
ented by means of non-negative integers i1 < i2 <
· · · < i2k satisfying

X =
k⋃

j=1

[i2j−1 + 1, i2j ].

In other words, we are decomposing X into the
union of k intervals, with k as small as possible.
It is easy to see that this decomposition is always
unique. We call set E = {i1, i2, . . . , i2k} the en-
dpoint set associated with X , and we call k the
fan-out of X , written f(X). Throughout this pa-
per, we will represent p as the collection of all
the position sets associated with the occurrences
of nonterminals in its right-hand side.

Let X1 and X2 be two disjoint position sets
(i.e., X1 ∩ X2 = ∅), with f(X1) = k1 and
f(X2) = k2 and with associated endpoint sets E1
and E2, respectively. We define the merge of X1
and X2 as the set X1 ∪ X2. We extend the po-
sition set and end-point set terminology to these
merge sets as well. It is easy to check that the en-
dpoint set associated to position set X1 ∪ X2 is
(E1∪E2)\ (E1∩E2). We say thatX1 andX2 are
2-combinable if f(X1 ∪X2) ≤ 2. We also say
that X1 and X2 are adjacent, written X1 ↔ X2,
if f(X1 ∪X2) ≤ max(k1, k2). It is not difficult
to see that X1 ↔ X2 if and only if X1 and X2 are
disjoint and |E1 ∩ E2| ≥ min(k1, k2). Note also
that X1 ↔ X2 always implies that X1 and X2 are
2-combinable (but not the other way around).

Let X be a collection of mutually disjoint posi-
tion sets. A reduction of X is the process of mer-
ging two position sets X1, X2 ∈ X , resulting in a
new collectionX ′ = (X \{X1, X2})∪{X1∪X2}.
The reduction is 2-feasible if X1 and X2 are 2-
combinable. A binarization of X is a sequence
of reductions resulting in a new collection with
two or fewer position sets. The binarization is
2-feasible if all of the involved reductions are 2-
feasible. Finally, we say that X is 2-feasible if
there exists at least one 2-feasible binarization for
X .

As an important remark, we observe that when
a collection X represents the position sets of all
the nonterminals in the right-hand side of a pro-
duction p with r(p) > 2, then a 2-feasible reduc-
tion merging XAi , XAj ∈ X can be interpreted
as follows. We replace p by means of a new pro-
duction p′ obtained from p by substituting Ai and
Aj with a fresh nonterminal symbol B, so that
r(p′) = r(p) − 1. Furthermore, we create a new
production p′′ with Ai and Aj in its right-hand
side, such that f(p′′) = f(B) ≤ 2 and r(p′′) = 2.
Productions p′ and p′′ together are equivalent to p,
but we have now achieved a local reduction in rank
of one unit.

Example 3 Let p be defined as in example 2 and
let X = {XA1 , XA2 , XA3}. We have that XA1
and XA2 are 2-combinable, and their merge is the
new position set X = XA1 ∪ XA2 = {1, 2, 3}.
This merge corresponds to a 2-feasible reduction
of X resulting in X ′ = {X,XA3}. Such a re-
duction corresponds to the construction of a new
production p′ : A→ g′(B,A3) with

g′(〈x1,1〉, 〈x3,1, x3,2〉) = 〈x1,1, x3,1bx3,2〉 ;

987



and a new production p′′ : B → g′′(A1, A2) with

g′′(〈x1,1, x1,2〉, 〈x2,1〉) = 〈x1,1ax2,1x1,2〉 . 2

It is easy to see that X is 2-feasible if and only
if there exists a binarization of p that does not in-
crease its fan-out.

Example 4 It has been shown in (Rambow
and Satta, 1999) that binarization of an
LCFRS G with f(G) = 2 and r(G) = 3
is always possible without increasing the
fan-out, and that if r(G) ≥ 4 then this is
no longer true. Consider the LCFRS pro-
duction p : A → g(A1, A2, A3, A4), with
g(〈x1,1, x1,2〉, 〈x2,1, x2,2〉, 〈x3,1, x3,2〉, 〈x4,1, x4,2〉) =
~α, ~α = 〈x1,1x2,1x3,1x4,1, x2,2x4,2x1,2x3,2〉. It is
not difficult to see that replacing any set of two or
three nonterminals in p’s right-hand side forces
the creation of a fresh nonterminal of fan-out
larger than two. 2

3.2 Greedy decision theorem

The binarization algorithm presented in this paper
proceeds by representing each LCFRS production
p as a collection of disjoint position sets, and then
finding a 2-feasible binarization of p. This binariz-
ation is computed deterministically, by an iterative
process that greedily chooses merges correspond-
ing to pairs of adjacent position sets.

The key idea behind the algorithm is based on a
theorem that guarantees that any merge of adjacent
sets preserves the property of 2-feasibility:

Theorem 1 LetX be a 2-feasible collection of po-
sition sets. The reduction of X by merging any
two adjacent position sets D1, D2 ∈ X results in
a new collection X ′ which is 2-feasible.

To prove Theorem 1 we consider that, sinceX is
2-feasible, there must exist at least one 2-feasible
binarization for X . We can write this binariza-
tion β as a sequence of reductions, where each re-
duction is characterized by a pair of position sets
(X1, X2) which are merged into X1 ∪X2, in such
a way that both each of the initial sets and the res-
ult of the merge have fan-out at most 2.

We will show that, under these conditions, for
every pair of adjacent position sets D1 and D2,
there exists a binarization that starts with the re-
duction merging D1 with D2.

Without loss of generality, we assume that
f(D1) ≤ f(D2) (if this inequality does not hold
we can always swap the names of the two position

sets, since the merging operation is commutative),
and we define a function hD1→D2 : 2

N → 2N as
follows:

• hD1→D2(X) = X; if D1 * X ∧D2 * X .

• hD1→D2(X) = X; if D1 ⊆ X ∧D2 ⊆ X .

• hD1→D2(X) = X ∪D1; if D1 * X ∧D2 ⊆
X .

• hD1→D2(X) = X \D1; if D1 ⊆ X ∧D2 *
X .

With this, we construct a binarization β′ from β
as follows:

• The first reduction in β′ merges the pair of
position sets (D1, D2),

• We consider the reductions in β in or-
der, and for each reduction o merging
(X1, X2), if X1 6= D1 and X2 6=
D1, we append a reduction o′ merging
(hD1→D2(X1), hD1→D2(X2)) to β

′.

We will now prove that, if β is a 2-feasible bin-
arization, then β′ is also a 2-feasible binarization.
To prove this, it suffices to show the following:2

(i) Every position set merged by a reduction in
β′ is either one of the original sets in X , or
the result of a previous merge in β′.

(ii) Every reduction in β′ merges a pair of posi-
tion sets (X1, X2) which are 2-combinable.

To prove (i) we note that by construction of β′,
if an operand of a merging operation in β′ is not
one of the original position sets in X , then it must
be an hD1→D2(X) for some X that appears as an
operand of a merging operation in β. Since the
binarization β is itself valid, this X must be either
one of the position sets in X , or the result of a
previous merge in the binarization β. So we divide
the proof into two cases:

• If X ∈ X : First of all, we note that X can-
not be D1, since the merging operations of β
that have D1 as an operand do not produce

2It is also necessary to show that no position set is merged
in two different reductions, but this easily follows from the
fact that hD1→D2(X) = hD1→D2(Y ) if and only if X ∪
D1 = Y ∪D1. Thus, two reductions in β can only produce
conflicting reductions in β′ if they merge two position sets
differing only by D1, but in this case, one of the reductions
must merge D1 so it does not produce any reduction in β′.

988



a corresponding operation in β′. If X equals
D2, then hD1→D2(X) is D1 ∪ D2, which is
the result of the first merging operation in β′.
Finally, if X is one of the position sets in X ,
and not D1 or D2, then hD1→D2(X) = X ,
so our operand is also one of the position sets
in X .

• If X is the result of a previous merging oper-
ation o in binarization β: Then, hD1→D2(X)
is the result of a previous merging operation
o′ in binarization β′, which is obtained by ap-
plying the function hD1→D2 to the operands
and result of o. 3

To prove (ii), we show that, under the assump-
tions of the theorem, the function hD1→D2 pre-
serves 2-combinability. Since two position sets of
fan-out ≤ 2 are 2-combinable if and only if they
are disjoint and the fan-out of their union is at most
2, it suffices to show that, for everyX,X1, X2 uni-
ons of one or more sets of X , having fan-out ≤ 2,
such that X1 6= D1, X2 6= D1 and X 6= D1;

(a) The function hD1→D2 preserves disjointness,
that is, if X1 and X2 are disjoint, then
hD1→D2(X1) and hD1→D2(X2) are disjoint.

(b) The function hD1→D2 is distributive with
respect to the union of position sets, that
is, hD1→D2(X1 ∪ X2) = hD1→D2(X1) ∪
hD1→D2(X2).

(c) The function hD1→D2 preserves the property
of having fan-out≤ 2, that is, ifX has fan-out
≤ 2, then hD1→D2(X) has fan-out ≤ 2.

If X1 and X2 do not contain D1 or D2, or if
one of the two unionsX1 orX2 containsD1∪D2,
properties (a) and (b) are trivial, since the function
hD1→D2 behaves as the identity function in these
cases.

It remains to show that (a) and (b) are true in the
following cases:

• X1 contains D1 but not D2, and X2 does not
contain D1 or D2:

3Except if one of the operands of the operation o was D1.
But in this case, if we call the other operand Z, then we have
that X = D1 ∪ Z. If Z contains D2, then X = D1 ∪
Z = hD1→D2(X) = hD1→D2(Z), so we apply this same
reasoning with hD1→D2(Z) where we cannot fall into this
case, since there can be only one merge operation in β that
uses D1 as an operand. If Z does not contain D2, then we
have that hD1→D2(X) = X \D1 = Z = hD1→D2(Z), so
we can do the same.

In this case, ifX1 andX2 are disjoint, we can
writeX1 = Y1∪D1, such that Y1, X2, D1 are
pairwise disjoint. By definition, we have that
hD1→D2(X1) = Y1, and hD1→D2(X2) =
X2, which are disjoint, so (a) holds.

Property (b) also holds because, with these
expressions for X1 and X2, we can calcu-
late hD1→D2(X1 ∪ X2) = Y1 ∪ X2 =
hD1→D2(X1) ∪ hD1→D2(X2).

• X1 containsD2 but notD1,X2 does not con-
tain D1 or D2:

In this case, if X1 and X2 are disjoint,
we can write X1 = Y1 ∪ D2, such that
Y1, X2, D1, D2 are pairwise disjoint. By
definition, hD1→D2(X1) = Y1 ∪ D2 ∪ D1,
and hD1→D2(X2) = X2, which are disjoint,
so (a) holds.

Property (b) also holds, since we can check
that hD1→D2(X1 ∪ X2) = Y1 ∪ X2 ∪ D2 ∪
D1 = hD1→D2(X1) ∪ hD1→D2(X2).

• X1 contains D1 but not D2, X2 contains D2
but not D1:

In this case, ifX1 andX2 are disjoint, we can
writeX1 = Y1∪D1 andX2 = Y2∪D2, such
that Y1, Y2, D1, D2 are pairwise disjoint. By
definition, we know that hD1→D2(X1) = Y1,
and hD1→D2(X2) = Y2 ∪ D1 ∪ D2, which
are disjoint, so (a) holds.

Finally, property (b) also holds in this case,
since hD1→D2(X1 ∪X2) = Y1 ∪X2 ∪D2 ∪
D1 = hD1→D2(X1) ∪ hD1→D2(X2).

This concludes the proof of (a) and (b).
To prove (c), we consider a position set X ,

union of one or more sets of X , with fan-out ≤ 2
and such that X 6= D1. First of all, we observe
that if X does not contain D1 or D2, or if it con-
tains D1 ∪ D2, (c) is trivial, because the function
hD1→D2 behaves as the identity function in this
case. So it remains to prove (c) in the cases where
X contains D1 but not D2, and where X contains
D2 but not D1. In any of these two cases, if we
call E(Y ) the endpoint set associated with an ar-
bitrary position set Y , we can make the following
observations:

1. Since X has fan-out ≤ 2, E(X) contains at
most 4 endpoints.

2. SinceD1 has fan-out f(D1),E(D1) contains
at most 2f(D1) endpoints.

989



3. SinceD2 has fan-out f(D2),E(D2) contains
at most 2f(D2) endpoints.

4. Since D1 and D2 are adjacent, we know
that E(D1) ∩ E(D2) contains at least
min(f(D1), f(D2)) = f(D1) endpoints.

5. Therefore, E(D1) \ (E(D1) ∩ E(D2)) can
contain at most 2f(D1) − f(D1) = f(D1)
endpoints.

6. On the other hand, sinceX contains only one
of D1 and D2, we know that the endpoints
where D1 is adjacent to D2 must also be en-
dpoints of X , so that E(D1) ∩ E(D2) ⊆
E(X). Therefore, E(X)\(E(D1)∩E(D2))
can contain at most 4− f(D1) endpoints.

Now, in the case where X contains D1 but not
D2, we know that hD1→D2(X) = X\D1. We cal-
culate a bound for the fan-out ofX\D1 as follows:
we observe that all the endpoints in E(X \ D1)
must be either endpoints of X or endpoints of
D1, since E(X) = (E(X \ D1) ∪ E(D1)) \
(E(X \ D1) ∩ E(D1)), so every position that is
in E(X \D1) but not in E(D1) must be in E(X).
But we also observe that E(X \ D1) cannot con-
tain any of the endpoints where D1 is adjacent to
D2 (i.e., the members of E(D1) ∩ E(D2)), since
X \D1 does not contain D1 or D2. Thus, we can
say that any endpoint of X \D1 is either a mem-
ber of E(D1) \ (E(D1) ∩ E(D2)), or a member
of E(X) \ (E(D1) ∩ E(D2)).

Thus, the number of endpoints in E(X \ D1)
cannot exceed the sum of the number of endpoints
in these two sets, which, according to the reason-
ings above, is at most 4 − f(D1) + f(D1) = 4.
Since E(X \D1) cannot contain more than 4 en-
dpoints, we conclude that the fan-out of X \ D1
is at most 2, so the function hD1→D2 preserves the
property of position sets having fan-out≤ 2 in this
case.

In the other case, where X contains D2 but not
D1, we follow a similar reasoning: in this case,
hD1→D2(X) = X ∪ D1. To bound the fan-out
of X ∪ D1, we observe that all the endpoints in
E(X ∪D1) must be either in E(X) or in E(D1),
since E(X ∪D1) = (E(X)∪E(D1)) \ (E(X)∩
E(D1)). But we also know that E(X ∪D1) can-
not contain any of the endpoints where D1 is adja-
cent to D2 (i.e., the members of E(D1)∩E(D2)),
since X ∪D1 contains both D1 and D2. Thus, we
can say that any endpoint of X ∪ D1 is either a

1: Function BINARIZATION(p)
2: A ← ∅; {working agenda}
3: R ← 〈〉; {empty list of reductions}
4: for all i from 1 to r(p) do
5: A ← A∪ {XAi};
6: while |A| > 2 and A contains two adjacent

position sets do
7: choose X1, X2 ∈ A such that X1 ↔ X2;
8: X ← X1 ∪X2;
9: A ← (A \ {X1, X2}) ∪ {X};

10: append (X1, X2) toR;
11: if |A| = 2 then
12: return R;
13: else
14: return fail;

Figure 1: Binarization algorithm for a production
p : A → g(A1, . . . , Ar(p)). Result is either a list
of reductions or failure.

member of E(D1)\ (E(D1)∩E(D2)), or a mem-
ber of E(X) \ (E(D1) ∩ E(D2)). Reasoning as
in the previous case, we conclude that the fan-out
of X ∪ D1 is at most 2, so the function hD1→D2
also preserves the property of position sets having
fan-out ≤ 2 in this case.

This concludes the proof of Theorem 1.

4 Binarization algorithm

Let p : A → g(A1, . . . , Ar(p)) be a production
with r(p) > 2 from some LCFRS with fan-out
not greater than 2. Recall from Subsection 3.1 that
each occurrence of nonterminal Ai in the right-
hand side of p is represented as a position setXAi .
The specification of an algorithm for finding a 2-
feasible binarization of p is reported in Figure 1.

The algorithm uses an agenda A as a working
set, where all position sets that still need to be pro-
cessed are stored. A is initialized with the posi-
tion sets XAi , 1 ≤ i ≤ r(p). At each step in the
algorithm, the size of A represents the maximum
rank among all productions that can be obtained
from the reductions that have been chosen so far in
the binarization process. The algorithm also uses
a list R, initialized as the empty list, where all re-
ductions that are attempted in the binarization pro-
cess are appended.

At each iteration, the algorithm performs a re-
duction by arbitrarily choosing a pair of adjacent
endpoint sets from the agenda and by merging
them. As already discussed in Subsection 3.1, this

990



corresponds to some specific transformation of the
input production p that preserves its generative ca-
pacity and that decreases its rank by one unit.

We stop the iterations of the algorithm when we
reach a state in which there are no more than two
position sets in the agenda. This means that the
binarization process has come to an end with the
reduction of p to a set of productions equivalent
to p and with rank and fan-out at most 2. This
set of productions can be easily constructed from
the output list R. We also stop the iterations in
case no adjacent pair of position sets can be found
in the agenda. If the agenda has more than two
position sets, this means that no binarization has
been found and the algorithm returns a failure.

4.1 Correctness

To prove the correctness of the algorithm in Fig-
ure 1, we need to show that it produces a 2-feasible
binarization of the given production p whenever
such a binarization exists. This is established by
the following theorem:

Theorem 2 LetX be a 2-feasible collection of po-
sition sets, such that the union of all sets in X is a
position set with fan-out ≤ 2. The procedure:

while ( X contains any pair of adjacent sets
X1, X2 ) reduce X by merging X1 with X2;

always finds a 2-feasible binarization of X .

In order to prove this, the loop invariant is that
X is a 2-feasible set, and that the union of all po-
sition sets in X has fan-out ≤ 2: reductions can
never change the union of all sets in X , and The-
orem 1 guarantees us that every change to the state
of X maintains 2-feasibility. We also know that
the algorithm eventually finishes, because every
iteration reduces the amount of position sets in X
by 1; and the looping condition will not hold when
the number of sets gets to be 1.

So it only remains to prove that the loop is only
exited if X contains at most two position sets. If
we show this, we know that the sequence of re-
ductions produced by this procedure is a 2-feasible
binarization. Since the loop is exited when X is 2-
feasible but it contains no pair of adjacent position
sets, it suffices to show the following:

Proposition 1 Let X be a 2-feasible collection of
position sets, such that the union of all the sets in
X is a position set with fan-out≤ 2. IfX has more
than two elements, then it contains at least a pair
of adjacent position sets. 2

Let X be a 2-feasible collection of more than
two position sets. Since X is 2-feasible, we know
that there must be a 2-feasible binarization of X .
Suppose that β is such a binarization, and let D1
and D2 be the two position sets that are merged in
the first reduction of β. Since β is 2-feasible, D1
and D2 must be 2-combinable.

If D1 and D2 are adjacent, our proposition is
true. If they are not adjacent, then, in order to be 2-
combinable, the fan-out of both position sets must
be 1: if any of them had fan-out 2, their union
would need to have fan-out > 2 for D1 and D2
not to be adjacent, and thus they would not be 2-
combinable. Since D1 and D2 have fan-out 1 and
are not adjacent, their sets of endpoints are of the
form {b1, b2} and {c1, c2}, and they are disjoint.

If we call EX the set of endpoints correspond-
ing to the union of all the position sets in X and
ED1D2 = {b1, b2, c1, c2}, we can show that at
least one of the endpoints in ED1D2 does not ap-
pear in EX , since we know that EX can have at
most 4 elements (as the union has fan-out ≤ 2)
and that it cannot equalED1D2 because this would
mean that X = {D1, D2}, and by hypothesis X
has more than two position sets. If we call this
endpoint x, this means that there must be a posi-
tion set D3 in X , different from D1 and D2, that
has x as one of its endpoints. Since D1 and D2
have fan-out 1, this implies that D3 must be ad-
jacent either to D1 or to D2, so we conclude the
proof.

4.2 Implementation and complexity

We now turn to the computational analysis of the
algorithm in Figure 1. We define the length of an
LCFRS production p, written |p|, as the sum of
the length of all strings αj in ~α in the definition
of the linear, non-erasing function associated with
p. Since we are dealing with LCFRS of fan-out at
most two, we easily derive that |p| = O(r(p)).

In the implementation of the algorithm it is con-
venient to represent each position set by means of
the corresponding endpoint set. Since at any time
in the computation we are only processing posi-
tion sets with fan-out not greater than two, each
endpoint set will contain at most four integers.

The for-loop at lines 4 and 5 in the algorithm
can be easily implemented through a left-to-right
scan of the characteristic string σN (p), detecting
the endpoint sets associated with each position set
XAi . This can be done in constant time for each

991



XAi , and thus in linear time in |p|.
At each iteration of the while-loop at lines 6

to 10 we have that A is reduced in size by one
unit. This means that the number of iterations is
bounded by r(p). We will show below that each
iteration of this loop can be executed in constant
time. We can therefore conclude that our binariz-
ation algorithm runs in optimal time O(|p|).

In order to run in constant time each single it-
eration of the while-loop at lines 6 to 10, we need
to perform some additional bookkeeping. We use
two arrays Ve and Va, whose elements are in-
dexed by the endpoints associated with character-
istic string σN (p), that is, integers i ∈ [0, |σN (p)|].
For each endpoint i, Ve[i] stores all the endpoint
sets that share endpoint i. Since each endpoint can
be shared by at most two endpoint sets, such a data
structure has sizeO(|p|). If there exists some posi-
tion setX inAwith leftmost endpoint i, then Va[i]
stores all the position sets (represented as endpoint
sets) that are adjacent to X . Since each position
set can be adjacent to at most four other position
sets, such a data structure has size O(|p|). Finally,
we assume we can go back and forth between po-
sition sets in the agenda and their leftmost end-
points.

We maintain arrays Ve and Va through the fol-
lowing simple procedures.

• Whenever a new position set X is added to
A, for each endpoint i of X we add X to
Ve[i]. We also check whether any position set
in Ve[i] other than X is adjacent to X , and
add these position sets to Va[il], where il is
the leftmost end point of X .

• Whenever some position set X is removed
from A, for each endpoint i of X we remove
X from Ve[i]. We also remove all of the posi-
tion sets in Va[il], where il is the leftmost end
point of X .

It is easy to see that, for any position set X which
is added/removed from A, each of the above pro-
cedures can be executed in constant time.

We maintain a set I of integer numbers i ∈
[0, |σN (p)|] such that i ∈ I if and only if Va[i] is
not empty. Then at each iteration of the while-loop
at lines 6 to 10 we pick up some index in I and re-
trieve at Va[i] some pairX,X ′ such thatX ↔ X ′.
Since X,X ′ are represented by means of endpoint
sets, we can compute the endpoint set ofX∪X ′ in
constant time. Removal of X,X ′ and addition of

X∪X ′ in our data structures Ve and Va is then per-
formed in constant time, as described above. This
proves our claim that each single iteration of the
while loop can be executed in constant time.

5 Discussion

We have presented an algorithm for the binariza-
tion of a LCFRS with fan-out 2 that does not in-
crease the fan-out, and have discussed how this
can be applied to improve parsing efficiency in
several practical applications. In the algorithm of
Figure 1, we can modify line 14 to return R even
in case of failure. If we do this, when a binariza-
tion with fan-out ≤ 2 does not exist the algorithm
will still provide us with a list of reductions that
can be converted into a set of productions equival-
ent to p with fan-out at most 2 and rank bounded
by some rb, with 2 < rb ≤ r(p). In case rb <
r(p), we are not guaranteed to have achieved an
optimal reduction in the rank, but we can still ob-
tain an asymptotic improvement in parsing time if
we use the new productions obtained in the trans-
formation.

Our algorithm has optimal time complexity,
since it works in linear time with respect to the
input production length. It still needs to be invest-
igated whether the proposed technique, based on
determinization of the choice of the reduction, can
also be used for finding binarizations for LCFRS
with fan-out larger than two, again without in-
creasing the fan-out. However, it seems unlikely
that this can still be done in linear time, since the
problem of binarization for LCFRS in general, i.e.,
without any bound on the fan-out, might not be
solvable in polynomial time. This is still an open
problem; see (Gómez-Rodrı́guez et al., 2009) for
discussion.

Acknowledgments

The first author has been supported by Ministerio
de Educación y Ciencia and FEDER (HUM2007-
66607-C04) and Xunta de Galicia (PGIDIT-
07SIN005206PR, INCITE08E1R104022ES,
INCITE08ENA305025ES, INCITE08PXIB-
302179PR and Rede Galega de Procesamento
da Linguaxe e Recuperación de Información).
The second author has been partially supported
by MIUR under project PRIN No. 2007TJN-
ZRE 002.

992



References

Pierre Boullier. 2004. Range concatenation grammars.
In H. Bunt, J. Carroll, and G. Satta, editors, New
Developments in Parsing Technology, volume 23 of
Text, Speech and Language Technology, pages 269–
289. Kluwer Academic Publishers.

Håkan Burden and Peter Ljunglöf. 2005. Parsing lin-
ear context-free rewriting systems. In IWPT05, 9th
International Workshop on Parsing Technologies.

David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd ACL, pages 263–270.

Carlos Gómez-Rodrı́guez, Marco Kuhlmann, Giorgio
Satta, and David Weir. 2009. Optimal reduction of
rule length in linear context-free rewriting systems.
In Proc. of the North American Chapter of the Asso-
ciation for Computational Linguistics - Human Lan-
guage Technologies Conference (NAACL’09:HLT),
Boulder, Colorado. To appear.

Aravind K. Joshi and Leon S. Levy. 1977. Constraints
on local descriptions: Local transformations. SIAM
J. Comput., 6(2):272–284.

Aravind K. Joshi, K. Vijay-Shanker, and David Weir.
1991. The convergence of mildly context-sensitive
grammatical formalisms. In P. Sells, S. Shieber, and
T. Wasow, editors, Foundational Issues in Natural
Language Processing. MIT Press, Cambridge MA.

Marco Kuhlmann and Giorgio Satta. 2009. Tree-
bank grammar techniques for non-projective de-
pendency parsing. In Proc. of the 12th Conference
of the European Chapter of the Association for Com-
putational Linguistics (EACL-09), pages 478–486,
Athens, Greece.

I. Dan Melamed. 2003. Multitext grammars and syn-
chronous parsers. In Proceedings of HLT-NAACL
2003.

Rebecca Nesson and Stuart M. Shieber. 2006. Simpler
TAG semantics through synchronization. In Pro-
ceedings of the 11th Conference on Formal Gram-
mar, Malaga, Spain, 29–30 July.

Owen Rambow and Giorgio Satta. 1999. Independent
parallelism in finite copying parallel rewriting sys-
tems. Theoretical Computer Science, 223:87–120.

Giorgio Satta. 1998. Trading independent for syn-
chronized parallelism in finite copying parallel re-
writing systems. Journal of Computer and System
Sciences, 56(1):27–45.

Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and
Tadao Kasami. 1991. On multiple context-free
grammars. Theoretical Computer Science, 88:191–
229.

K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi.
1987. Characterizing structural descriptions pro-
duced by various grammatical formalisms. In Pro-
ceedings of the 25th Meeting of the Association for
Computational Linguistics (ACL’87).

Hao Zhang, Daniel Gildea, and David Chiang. 2008.
Extracting synchronous grammar rules from word-
level alignments in linear time. In 22nd Inter-
national Conference on Computational Linguistics
(Coling), pages 1081–1088, Manchester, England,
UK.

993


