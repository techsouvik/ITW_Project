






















































Realistic Grammar Error Simulation using Markov Logic


Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 81–84,
Suntec, Singapore, 4 August 2009. c©2009 ACL and AFNLP

Realistic Grammar Error Simulation using Markov Logic 

 

Sungjin Lee 

Pohang University of Science and 

Technology 

Pohang, Korea 

junion@postech.ac.kr  

Gary Geunbae Lee 

Pohang University of Science and 

Technology 

Pohang, Korea 

gblee@postech.ac.kr 

 

  

 

Abstract 

The development of Dialog-Based Computer-

Assisted Language Learning (DB-CALL) sys-

tems requires research on the simulation of 

language learners. This paper presents a new 

method for generation of grammar errors, an 

important part of the language learner simula-

tor. Realistic errors are generated via Markov 

Logic, which provides an effective way to 

merge a statistical approach with expert know-

ledge about the grammar error characteristics 

of language learners. Results suggest that the 

distribution of simulated grammar errors gen-

erated by the proposed model is similar to that 

of real learners. Human judges also gave con-

sistently close judgments on the quality of the 

real and simulated grammar errors. 

1 Introduction 

Second Language Acquisition (SLA) researchers 

have claimed that feedback provided during con-

versational interaction facilitates the acquisition 

process. Thus, interest in developing Dialog-

Based Computer Assisted Language Learning 

(DB-CALL) systems is rapidly increasing. How-

ever, developing DB-CALL systems takes a long 

time and entails a high cost in collecting learners’ 
data. Also, evaluating the systems is not a trivial 

task because it requires numerous language 

learners with a wide range of proficiency levels 

as subjects.  

While previous studies have considered user 

simulation in the development and evaluation of 

spoken dialog systems (Schatzmann et al., 2006), 

they have not yet simulated grammar errors be-

cause those systems were assumed to be used by 

native speakers, who normally produce few 

grammar errors in utterances. However, as tele-

phone-based information access systems become 

more commonly available to the general public, 

the inability to deal with non-native speakers is 

becoming a serious limitation since, at least for 

some applications, (e.g. tourist information, le-

gal/social advice) non-native speakers represent 

a significant portion of the everyday user popula-

tion. Thus, (Raux and Eskenazi, 2004) conducted 

a study on adaptation of spoken dialog systems 

to non-native users. In particular, DB-CALL sys-

tems should obviously deal with grammar errors 

because language learners naturally commit nu-

merous grammar errors. Thus grammar error si-

mulation should be embedded in the user simula-

tion for the development and evaluation of such 

systems. 

In Foster’s (2007) pioneering work, she de-
scribed a procedure which automatically intro-

duces frequently occurring grammatical errors 

into sentences to make ungrammatical training 

data for a robust parser. However the algorithm 

cannot be directly applied to grammar error gen-

eration for language learner simulation for sever-

al reasons. First, it either introduces one error per 

sentence or none, regardless of how many words 

of the sentence are likely to generate errors. 

Second, it determines which type of error it will 

create only by relying on the relative frequencies 

of error types and their relevant parts of speech. 

This, however, can result in unrealistic errors. As 

exemplified in Table 1, when the algorithm tries 

to create an error by deleting a word, it would 

probably omit the word ‘go’ because verb is one 
of the most frequent parts of speech omitted re-

sulting in an unrealistic error like the first simu-

lated output. However, Korean/Japanese lan-

guage learners of English tend to make subject-

verb agreement errors, omission errors of the 

preposition of prepositional verbs, and omission 

errors of articles because their first language 

does not have similar grammar rules so that they 

may be slow on the uptake of such constructs. 

Thus, they often commit errors like the second 

simulated output.  

81



This paper develops an approach to statistical 

grammar error simulation that can incorporate 

this type of knowledge about language learners’ 
error characteristics and shows that it does in-

deed result in realistic grammar errors. The ap-

proach is based on Markov logic, a representa-

tion language that combines probabilistic graphi-

cal models and first-order logic (Richardson and 

Domingos, 2006). Markov logic enables concise 

specification of very complex models. Efficient 

open-source Markov logic learning and inference 

algorithms were used to implement our solution.  

We begin by describing the overall process of 

grammar error simulation and then briefly re-

viewing the necessary background in Markov 

logic. We then describe our Markov Logic Net-

work (MLN) for grammar error simulation. Fi-

nally, we present our experiments and results. 

2 Overall process of grammar error si-

mulation 

The task of grammar error simulation is to gen-

erate an ill-formed sentence when given a well-

formed input sentence. The generation procedure 

involves three steps: 1) Generating probability 

over error types for each word of the well-

formed input sentence through MLN inference 2) 

Determining an error type by sampling the gen-

erated probability for each word 3) Creating an 

ill-formed output sentence by realizing the cho-

sen error types (Figure 1).  

3 Markov Logic 

Markov logic is a probabilistic extension of finite 

first-order logic (Richardson and Domingos, 

2006). An MLN is a set of weighted first-order 

clauses. Together with a set of constants, it de-

fines a Markov network with one node per 

ground atom and one feature per ground clause. 

The weight of a feature is the weight of the first-

order clause that originated it. The probability of 

a state x in such a network is given by ܲ(ݔ)  =
σ) ݌ݔ݁ (ܼ/1)  ݅ݓ ݂݅ ݅(ݔ) ), where ܼ  is a normali-
zation constant, ݅ݓ  is the weight of the ݅th clause, ݂݅  =  1 if the ݅th clause is true, and ݂݅  =  0 oth-
erwise.  

Markov logic makes it possible to compactly 

specify probability distributions over complex 

relational domains. We used the learning and 

inference algorithms provided in the open-source 

Alchemy package (Kok et al., 2006).  In particu-

lar, we performed inference using the belief 

propagation algorithm (Pearl, 1988), and genera-

tive weight learning. 

4 An MLN for Grammar Error Simula-

tion 

This section presents our MLN implementation 

which consists of three components: 1) Basic 

formulas based on parts of speech, which are 

comparable to Foster’s method 2) Analytic for-
mulas drawn from expert knowledge obtained by 

error analysis on a learner corpus 3) Error limit-

ing formulas that penalize statistical model’s 
over-generation of nonsense errors.  

4.1 Basic formulas 

Error patterns obtained by error analysis, which 

might capture a lack or an over-generalization of 

knowledge of a particular construction, cannot 

explain every error that learners commit. Be-

cause an error can take the form of a perfor-

mance slip which can randomly occur due to 

carelessness or tiredness, more general formulas 

are needed as a default case. The basic formulas 

are represented by the simple rule: 
 ܲ݃ܽܶݏ݋ሺݏ, ݅, ,ݏ)݁݌ݕܶݎ݋ݎݎܧ ሻ ݐ݌+ ݅,  (ݐ݁+

where all free variables are implicitly universally 

quantified. The “+ݐ݌,  notation signifies ”ݐ݁+
that the MLN contains an instance of this rule for 

each (part of speech, error type) pair. The evi-

Input sentence 
He wants to go to a movie theater 

Unrealistic simulated output 
He wants to to a movie theater 

Realistic simulated output 

He want go to movie theater 

Table 1: Examples of simulated outputs  

Figure 1: An example process of grammar error simulation 

82



dence predicate in this case is ܲݏ)݃ܽܶݏ݋,  ,(ݐ݌,݅
which is true iff the ݅th position of the sentence ݏ 
has the part of speech ݐ݌. The query predicate is ݏ)݁݌ݕܶݎ݋ݎݎܧ, ݅,  It is true iff the ݅th position .(ݐ݁
of the sentence ݏ has the error type ݁ݐ, and infer-
ring it returns the probability that the word at 

position ݅ would commit an error of type ݁ݐ.  
4.2 Analytic formulas 

On top of the basic formulas, analytic formulas 

add concrete knowledge of realistic error charac-

teristics of language learners. Error analysis and 

linguistic differences between the first language 

and the second language can identify various 

error sources for each error type. We roughly 

categorize the error sources into three groups for 

explanation: 1) Over-generalization of the rules 

of the second language 2) Lack of knowledge of 

some rules of the second language 3) Applying 

rules and forms of the first language into the 

second language. 

Often, English learners commit pluralization 

error with irregular nouns. This is because they 

over-generalize the pluralization rule, i.e. attach-

ing ‘s/es’, so that they apply the rule even to ir-
regular  nouns such  as ‘fish’ and ‘feet’ etc. This 
characteristic is captured by the simple formula: 
 ݊ݑ݋݈ܰܽݎݑ݈ܲݎ݈ܽݑ݃݁ݎݎܫሺݏ, ݅ሻ ר ,ݏሺ݃ܽܶݏ݋ܲ ݅,ܰܰܵሻ 
 ݏ)݁݌ݕܶݎ݋ݎݎܧ,  (ܤܷܵ_ܯܷܰ_ܰ,݅

where ݊ݑ݋݈ܰܽݎݑ݈ܲݎ݈ܽݑ݃݁ݎݎܫሺݏ, ݅ሻ is true iff the ݅th word of the sentence ݏ is an irregular plural 
and N_NUM_SUB is the abbreviation for substi-

tution by noun number error.  

One trivial error caused by a lack of know-

ledge of the second language is using the singu-

lar noun form for weekly events: 
 ܹ݀ݎ݋ሺݏ, ݅ െ 1, ሻ݊݋ ר  ,ݏሺ݊ݑ݋ܰݕܽܦ ݅ሻר ,ݏሺ݃ܽܶݏ݋ܲ ݅,ܰܰܵሻ ݏ)݁݌ݕܶݎ݋ݎݎܧ,  (ܤܷܵ_ܯܷܰ_ܰ,݅
where ܹ݀ݎ݋ሺݏ, ݅ െ 1, ݅ ሻ is true iff the݊݋ െ 1th 
word is ‘on’ and ݊ݑ݋ܰݕܽܦሺݏ, ݅ሻ is true iff the ݅th word of the sentence ݏ is a noun describing 
day like Sunday(s). Another example is use of 

plurals behind ‘every’ due to the ignorance that a 
noun modified by ‘every’ should be singular: 
 ܹ݀ݎ݋ሺݏ,݀݅, ሻݕݎ݁ݒ݁ ר  ሻ݅݊,݅݀,ݏሺ݈ܴ݁ݎ݁݊݅݉ݎ݁ݐ݁ܦ
 (ܤܷܵ_ܯܷܰ_ܰ,݅݊,ݏ)݁݌ݕܶݎ݋ݎݎܧ 

where ݈ܴ݁ݎ݁݊݅݉ݎ݁ݐ݁ܦሺݏ,݀݅,݊݅ሻ  is true iff the ݀݅th word is the determiner of the ݊݅th word. 
An example of errors by applying the rules of 

the first language is that Korean/Japanese often 

allows omission of the subject of a sentence; thus, 

they easily commit the subject omission error. 

The following formula is for the case: 
 ܵݐ݆ܾܿ݁ݑሺݏ, ݅ሻ ݏ)݁݌ݕܶݎ݋ݎݎܧ,  (ܮܧܦ_ܥܺܮ_ܰ,݅

where ܵݐ݆ܾܿ݁ݑሺݏ, ݅ሻ is true iff the ݅th word is the 
subject and N_LXC_DEL is the abbreviation for 

deletion by noun lexis error.
1
 

4.3 Error limiting formulas 

A number of elementary formulas explicitly 

stated as hard formulas prevent the MLN from 

generating improbable errors that might result 

from over-generations of the statistical model. 

For example, a verb complement error should not 

have a probability at the words that are not com-

plements of a verb: 
 !ܸ݁ݐ݈݊݁݉݁݌݉݋ܥܾݎሺݏ, ,݅ݒ ܿ݅ሻ 
 !ݏ)݁݌ݕܶݎ݋ݎݎܧ,  .(ܤܷܵ_ܲܯܥ_ܸ,݅ܿ

where “!” denotes logically ‘not’ and “.” at the 
end signifies that it is a hard formula. Hard formu-

las are given maximum weight during inference. ܸ݁ݐ݈݊݁݉݁݌݉݋ܥܾݎሺݏ, ,݅ݒ ܿ݅ሻ  is true iff the ܿ݅ th 
word is a complement of the verb at the ݅ݒth po-
sition and V_CMP_SUB is the abbreviation for 

substitution by verb complement error. 

5 Experiments  

Experiments used the NICT JLE Corpus, which 

is speech samples from an English oral profi-

ciency interview test, the ACTFL-ALC Standard 

Speaking Test (SST). 167 of the files are error 

annotated. The error tagset consists of 47 tags 

that are described in Izumi (2005). We appended 

structural type of errors (substitution, addition, 

deletion) to the original error types because 

structural type should be determined when creat-

ing an error. For example, V_TNS_SUB consists 

of the original error type V_TNS (verb tense) and 

structural type SUB (substitution).  Level-

specific language learner simulation was accom-

plished by dividing the 167 error annotated files 

into 3 level groups: Beginner(level1-4), Interme-

diate(level5-6), Advanced(level7-9).  

The grammar error simulation was compared 

with real learners’ errors and the baseline model 
using only basic formulas comparable to Foster’s 
algorithm, with 10-fold cross validations per-

formed for each group. The validation results 

were added together across the rounds to com-

pare the number of simulated errors with the 

number of real errors. Error types that occurred 

less than 20 times were excluded to improve re-

liability. Result graphs suggest that the distribu-

tion of simulated grammar errors generated by 

the proposed model using all formulas is similar 

to that of real learners for all level groups and the 

                                                 
1
 Because space is limited, all formulas can be found at 

http://isoft.postech.ac.kr/ges/grm_err_sim.mln 

83



proposed model outperforms the baseline model 

using only the basic formulas. The Kullback-

Leibler divergences, a measure of the difference 

between two probability distributions, were also 

measured for quantitative comparison. For all 

level groups, the Kullback-Leibler divergence of 

the proposed model from the real is less than that 

of the baseline model (Figure 2). 

Two human judges verified the overall realism 

of the simulated errors. They evaluated 100 ran-

domly chosen sentences consisting of 50 sen-

tences each from the real and simulated data. The 

sequence of the test sentences was mixed so that 

the human judges did not know whether the 

source of the sentence was real or simulated. 

They evaluated sentences with a two-level scale 

(0: Unrealistic, 1: Realistic). The result shows 

that the inter evaluator agreement (kappa) is 

moderate and that both judges gave relatively 

close judgments on the quality of the real and 

simulated data (Table 2). 

6 Summary and Future Work  

This paper introduced a somewhat new research 

topic, grammar error simulation. Expert know-

ledge of error characteristics was imported to 

statistical modeling using Markov logic, which 

provides a theoretically sound way of encoding 

knowledge into probabilistic first order logic. 

Results indicate that our method can make an 

error distribution more similar to the real error 

distribution than the baseline and that the quality 

of simulated sentences is relatively close to that 

of real sentences in the judgment of human eva-

luators. Our future work includes adding more 

expert knowledge through error analysis to in-

crementally improve the performance. Further-

more, actual development and evaluation of a 

DB-CALL system will be arranged so that we 

may investigate how much the cost of collecting 

data and evaluation would be reduced by using 

language learner simulation. 

Acknowledgement  

This research was supported by the MKE (Ministry of 

Knowledge Economy), Korea, under the ITRC (In-

formation Technology Research Center) support pro-

gram supervised by the IITA (Institute for Informa-

tion Technology Advancement) (IITA-2009-C1090-

0902-0045). 

References  

Foster, J. 2007. Treebanks Gone Bad: Parser evalua-
tion and retraining using a treebank of ungrammat-
ical sentences. IJDAR, 10(3-4), 129-145. 

Izumi, E et al. 2005. Error Annotation for Corpus of 
Japanese Learner English. In Proc. International 
Workshop on Linguistically Interpreted Corpora  

Kok, S. et al. 2006. The Alchemy system for statistic-

al relational AI. http://alchemy.cs.washington.edu/. 

Pearl, J. 1988. Probabilistic Reasoning in Intelligent 

Systems Morgan Kaufmann. 

Raux, A. and Eskenazi, M. 2004. Non-Native Users in 

the Let's Go!! Spoken Dialogue System: Dealing 

with Linguistic Mismatch, HLT/NAACL. 

Richardson, M. and Domingos, P. 2006. Markov logic 

networks. Machine Learning, 62(1):107-136. 

Schatzmann, J. et al. 2006. A survey of statistical user 

simulation techniques for reinforcement-learning 

of dialogue management strategies, The Know-

ledge Engineering ReviewVol–  

 
Advanced Level:  

DKL (Real || Proposed)=0.068, DKL (Real || Baseline)=0.122 

 
Intermediate Level: 

DKL (Real || Proposed)=0.075, DKL (Real || Baseline)=0.142 

Beginner Level: 
DKL (Real || Proposed)=0.075, DKL (Real || Baseline)=0.092 

Figure 2: Comparison between the distributions of the 

real and simulated data 

 Human 1 Human 2 Average Kappa 

Real 0.84 0.8 0.82 0.46 

Simulated 0.8 0.8 0.8 0.5 

Table 2: Human evaluation results 

84


